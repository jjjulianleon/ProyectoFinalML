{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final ML: Clustering y Semi-Supervised Learning\n",
    "## An√°lisis de Cooperativas del Segmento 1 en Ecuador\n",
    "\n",
    "---\n",
    "\n",
    "**Curso:** Machine Learning\n",
    "\n",
    "**Objetivo:** Agrupar cooperativas de ahorro y cr√©dito seg√∫n caracter√≠sticas financieras y validar coherencia de clusters contra ratings reales.\n",
    "\n",
    "**Fechas:** Noviembre 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Tabla de Contenidos\n",
    "\n",
    "1. **Setup e Instalaci√≥n** - Configuraci√≥n inicial\n",
    "2. **Parte 1: Obtenci√≥n de Datos** - Web scraping y extracci√≥n\n",
    "3. **Parte 2: An√°lisis Exploratorio (EDA)** - Exploraci√≥n de datos\n",
    "4. **Parte 3: Clustering No Supervisado** - K-Means, Agglomerative, DBSCAN\n",
    "5. **Parte 4: Semi-Supervised Learning** - Label Propagation, Self-Training\n",
    "6. **Resultados y Conclusiones** - An√°lisis final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ SETUP E INSTALACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup para Google Colab (comentar si es local)\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üì± Ejecut√°ndose en Google Colab\")\n",
    "    \n",
    "    # Clonar repositorio\n",
    "    !git clone https://github.com/jjjulianleon/ProyectoFinalML.git\n",
    "    %cd ProyectoFinalML\n",
    "    \n",
    "    # Instalar dependencias\n",
    "    !pip install -q -r requirements.txt\n",
    "    \n",
    "    print(\"‚úì Dependencias instaladas\")\n",
    "else:\n",
    "    print(\"üíª Ejecut√°ndose localmente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurar estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Agregar src al path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "# Imports de m√≥dulos locales\n",
    "from etl.generate_sample_data import generate_sample_cooperativas_data\n",
    "from models.clustering import ClusteringAnalyzer\n",
    "from models.semi_supervised import SemiSupervisedLearner\n",
    "\n",
    "print(\"‚úì Imports completados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Crear directorio para figuras\n",
    "Path('figures').mkdir(exist_ok=True)\n",
    "Path('data/processed').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Configuraci√≥n completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2Ô∏è‚É£ PARTE 1: OBTENCI√ìN Y PREPARACI√ìN DE DATOS\n\n**EXTRACCI√ìN AUTOM√ÅTICA 100%:**\n- Descarga autom√°tica de PDFs desde URLs\n- Extracci√≥n de texto con pdfplumber\n- Procesamiento con OpenAI API (LLM)\n- Generaci√≥n de dataset estructurado"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# OPCI√ìN 1: Ejecutar pipeline ETL completo (RECOMENDADO para datos reales)\nUSE_REAL_DATA = True  # Cambiar a True para usar datos reales\n\n# Detectar si estamos en Google Colab\nimport sys\nIN_COLAB = 'google.colab' in sys.modules\n\nif USE_REAL_DATA:\n    print(\"=\"*70)\n    print(\"üöÄ EJECUTANDO PIPELINE ETL - EXTRACCI√ìN AUTOM√ÅTICA\")\n    print(\"=\"*70)\n    \n    # Configurar API Key en Google Colab\n    if IN_COLAB:\n        import os\n        from getpass import getpass\n        \n        print(\"\\nüîë CONFIGURACI√ìN DE API KEY\")\n        print(\"=\"*70)\n        print(\"Para usar extracci√≥n autom√°tica con OpenAI, necesitas una API key.\")\n        print(\"Obt√©n una en: https://platform.openai.com/api-keys\")\n        print(\"\\nOpciones:\")\n        print(\"  1. Usar Google Colab Secrets (recomendado)\")\n        print(\"     - Click en üîë (llave) en panel izquierdo\")\n        print(\"     - Agregar secreto: OPENAI_API_KEY\")\n        print(\"  2. Ingresar manualmente (se borrar√° al reiniciar)\")\n        print(\"=\"*70)\n        \n        # Intentar obtener de Colab Secrets\n        api_key = None\n        try:\n            from google.colab import userdata\n            api_key = userdata.get('OPENAI_API_KEY')\n            if api_key:\n                print(\"‚úì API Key obtenida de Google Colab Secrets\\n\")\n        except Exception as e:\n            print(f\"‚ö†Ô∏è  No se pudo acceder a Colab Secrets: {e}\")\n            print(\"   Ingresa la API key manualmente\\n\")\n        \n        # Si no est√° en secrets, pedir al usuario\n        if not api_key:\n            api_key = getpass(\"Ingresa tu OpenAI API Key: \")\n            print(\"‚úì API Key ingresada\\n\")\n        \n        os.environ['OPENAI_API_KEY'] = api_key\n        os.environ['MODEL_NAME'] = 'gpt-4o-mini'\n    \n    from etl.run_etl_pipeline import run_etl_pipeline\n    \n    # Ejecutar pipeline (descarga + extracci√≥n con OpenAI)\n    df = run_etl_pipeline(\n        urls_file=\"data/cooperativas_urls.txt\",\n        output_csv=\"data/processed/cooperativas_data.csv\",\n        download_dir=\"data/raw\"\n    )\n    \n    if df is None or df.empty:\n        print(\"\\n‚ö†Ô∏è  No se pudieron extraer datos reales. Usando datos de ejemplo...\")\n        from etl.generate_sample_data import generate_sample_cooperativas_data\n        df = generate_sample_cooperativas_data(n_samples=50)\n    \nelse:\n    # OPCI√ìN 2: Usar datos de ejemplo (m√°s r√°pido para pruebas)\n    print(\"üìä Generando datos de ejemplo...\")\n    from etl.generate_sample_data import generate_sample_cooperativas_data\n    df = generate_sample_cooperativas_data(n_samples=50)\n\nprint(f\"\\n‚úì Dataset cargado: {df.shape}\")\nprint(f\"\\nüìä Distribuci√≥n de Ratings:\")\nprint(df['rating'].value_counts().sort_index())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionar datos\n",
    "print(\"üìã Primeras filas del dataset:\")\n",
    "display(df.head(10))\n",
    "\n",
    "print(\"\\nüìä Informaci√≥n del dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print(\"üìà Estad√≠sticas Descriptivas:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(\"\\n‚ùì Valores Faltantes:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar datos procesados\n",
    "df.to_csv('data/processed/cooperativas_data.csv', index=False)\n",
    "print(\"‚úì Datos guardados en: data/processed/cooperativas_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ PARTE 2: AN√ÅLISIS EXPLORATORIO (EDA)\n",
    "\n",
    "Exploraci√≥n no supervisada de los datos para identificar patrones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar variables num√©ricas\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Variables num√©ricas a analizar ({len(numeric_cols)}):\")\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n por rating\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    for rating in df['rating'].unique():\n",
    "        data = df[df['rating'] == rating][col]\n",
    "        axes[idx].hist(data, alpha=0.5, label=f'Rating {rating}')\n",
    "    \n",
    "    axes[idx].set_title(col, fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Valor')\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/01_distribucion_por_rating.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: figures/01_distribucion_por_rating.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlaci√≥n - Indicadores Financieros', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/02_matriz_correlacion.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: figures/02_matriz_correlacion.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de correlaciones altas\n",
    "print(\"üîó Correlaciones m√°s altas (excluyendo diagonal):\")\n",
    "corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_pairs.append({\n",
    "            'variable1': corr_matrix.columns[i],\n",
    "            'variable2': corr_matrix.columns[j],\n",
    "            'correlacion': corr_matrix.iloc[i, j]\n",
    "        })\n",
    "\n",
    "corr_pairs_df = pd.DataFrame(corr_pairs).sort_values('correlacion', ascending=False, key=abs)\n",
    "display(corr_pairs_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducci√≥n dimensional con t-SNE\n",
    "print(\"üîÑ Aplicando t-SNE para visualizaci√≥n...\")\n",
    "\n",
    "# Normalizar datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Aplicar t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "print(\"‚úì t-SNE completado\")\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=pd.Categorical(df['rating']).codes,\n",
    "                      cmap='viridis', s=100, alpha=0.6, edgecolors='black', linewidth=1)\n",
    "\n",
    "# Agregar etiquetas de rating\n",
    "for rating in df['rating'].unique():\n",
    "    mask = df['rating'] == rating\n",
    "    plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1], label=f'Rating {rating}', s=100, alpha=0.6)\n",
    "\n",
    "plt.xlabel(f'Dimensi√≥n 1', fontsize=11)\n",
    "plt.ylabel(f'Dimensi√≥n 2', fontsize=11)\n",
    "plt.title('t-SNE: Visualizaci√≥n de Cooperativas por Rating', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/03_tsne_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: figures/03_tsne_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ PARTE 3: CLUSTERING NO SUPERVISADO\n",
    "\n",
    "Aplicamos m√∫ltiples algoritmos de clustering y evaluamos su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar analizador de clustering\n",
    "print(\"ü§ñ Inicializando analizador de clustering...\\n\")\n",
    "\n",
    "analyzer = ClusteringAnalyzer(df[numeric_cols], random_state=RANDOM_STATE)\n",
    "X_scaled = analyzer.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar k √≥ptimo para K-Means\n",
    "print(\"üìä Evaluando n√∫mero √≥ptimo de clusters (k)...\\n\")\n",
    "\n",
    "k_results = analyzer.find_optimal_k(k_range=range(2, 11))\n",
    "display(k_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar m√©tricas de k √≥ptimo\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Silhouette Score\n",
    "axes[0].plot(k_results['k'], k_results['silhouette'], 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('N√∫mero de Clusters (k)', fontsize=11)\n",
    "axes[0].set_ylabel('Silhouette Score', fontsize=11)\n",
    "axes[0].set_title('Silhouette Score vs k', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].set_xticks(k_results['k'])\n",
    "\n",
    "# Davies-Bouldin Index\n",
    "axes[1].plot(k_results['k'], k_results['davies_bouldin'], 'rs-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('N√∫mero de Clusters (k)', fontsize=11)\n",
    "axes[1].set_ylabel('Davies-Bouldin Index', fontsize=11)\n",
    "axes[1].set_title('Davies-Bouldin Index vs k (menor es mejor)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].set_xticks(k_results['k'])\n",
    "\n",
    "# Calinski-Harabasz Index\n",
    "axes[2].plot(k_results['k'], k_results['calinski_harabasz'], 'gs-', linewidth=2, markersize=8)\n",
    "axes[2].set_xlabel('N√∫mero de Clusters (k)', fontsize=11)\n",
    "axes[2].set_ylabel('Calinski-Harabasz Index', fontsize=11)\n",
    "axes[2].set_title('Calinski-Harabasz Index vs k', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(alpha=0.3)\n",
    "axes[2].set_xticks(k_results['k'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_elbow_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: figures/04_elbow_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar k √≥ptimo (basado en Silhouette Score)\n",
    "optimal_k = k_results.loc[k_results['silhouette'].idxmax(), 'k'].astype(int)\n",
    "print(f\"‚úì k √≥ptimo seleccionado: {optimal_k}\")\n",
    "print(f\"  Silhouette Score: {k_results.loc[k_results['k'] == optimal_k, 'silhouette'].values[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar K-Means\n",
    "print(f\"\\n{'='*50}\")\n",
    "kmeans_labels, kmeans_metrics = analyzer.kmeans_clustering(n_clusters=optimal_k)\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Agglomerative Clustering\n",
    "print(f\"\\n{'='*50}\")\n",
    "agg_labels, agg_metrics = analyzer.agglomerative_clustering(n_clusters=optimal_k)\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar DBSCAN\n",
    "print(f\"\\n{'='*50}\")\n",
    "dbscan_labels, dbscan_metrics = analyzer.dbscan_clustering(eps=0.8, min_samples=4)\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de m√©tricas de clustering\n",
    "print(\"\\nüìä RESUMEN DE M√âTRICAS DE CLUSTERING\\n\")\n",
    "clustering_summary = analyzer.get_summary()\n",
    "display(clustering_summary)\n",
    "\n",
    "# Guardar resumen\n",
    "clustering_summary.to_csv('data/processed/clustering_metrics.csv', index=False)\n",
    "print(\"\\n‚úì Resumen guardado: data/processed/clustering_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar clusters en t-SNE\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# K-Means\n",
    "scatter1 = axes[0].scatter(X_tsne[:, 0], X_tsne[:, 1], c=kmeans_labels,\n",
    "                           cmap='viridis', s=100, alpha=0.6, edgecolors='black', linewidth=1)\n",
    "axes[0].set_title(f'K-Means (k={optimal_k})', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('t-SNE 1')\n",
    "axes[0].set_ylabel('t-SNE 2')\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Agglomerative\n",
    "scatter2 = axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=agg_labels,\n",
    "                           cmap='plasma', s=100, alpha=0.6, edgecolors='black', linewidth=1)\n",
    "axes[1].set_title(f'Agglomerative Clustering (k={optimal_k})', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('t-SNE 1')\n",
    "axes[1].set_ylabel('t-SNE 2')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# DBSCAN\n",
    "scatter3 = axes[2].scatter(X_tsne[:, 0], X_tsne[:, 1], c=dbscan_labels,\n",
    "                           cmap='cool', s=100, alpha=0.6, edgecolors='black', linewidth=1)\n",
    "axes[2].set_title(f'DBSCAN', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('t-SNE 1')\n",
    "axes[2].set_ylabel('t-SNE 2')\n",
    "plt.colorbar(scatter3, ax=axes[2], label='Cluster')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/05_clustering_results_tsne.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: figures/05_clustering_results_tsne.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n con ratings reales\n",
    "print(\"\\nüìä COMPARACI√ìN CON RATINGS REALES\\n\")\n",
    "\n",
    "# Codificar ratings a n√∫meros\n",
    "le = LabelEncoder()\n",
    "ratings_encoded = le.fit_transform(df['rating'])\n",
    "\n",
    "comparison = analyzer.compare_with_ratings(ratings_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n - K-Means vs Ratings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "algorithms = ['K-Means', 'Agglomerative', 'DBSCAN']\n",
    "labels_list = [kmeans_labels, agg_labels, dbscan_labels]\n",
    "\n",
    "for idx, (algo_name, labels) in enumerate(zip(algorithms, labels_list)):\n",
    "    cm = confusion_matrix(ratings_encoded, labels)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx], cbar=False)\n",
    "    axes[idx].set_title(f'{algo_name}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Rating Real')\n",
    "    axes[idx].set_xlabel('Cluster Predicho')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/06_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: figures/06_confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ PARTE 4: SEMI-SUPERVISED LEARNING\n",
    "\n",
    "Comparamos diferentes enfoques variando el ratio de datos etiquetados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar learner semi-supervisado\n",
    "print(\"ü§ñ Inicializando Semi-Supervised Learner...\\n\")\n",
    "\n",
    "semi_learner = SemiSupervisedLearner(df[numeric_cols + ['rating']], \n",
    "                                      target_column='rating',\n",
    "                                      random_state=RANDOM_STATE)\n",
    "X_semi, y_semi = semi_learner.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline supervisado\n",
    "print(\"‚ñ∂ Entrenando BASELINE SUPERVISADO\\n\")\n",
    "baseline = semi_learner.supervised_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n variando ratios\n",
    "print(\"‚ñ∂ Evaluando Semi-Supervised Learning con diferentes ratios\\n\")\n",
    "\n",
    "ratios = [0.1, 0.2, 0.3, 0.5, 0.7]\n",
    "results_df = semi_learner.compare_ratios(ratios=ratios)\n",
    "\n",
    "print(\"\\n‚úì Evaluaci√≥n completada\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados semi-supervised\n",
    "results_df.to_csv('data/processed/semi_supervised_results.csv', index=False)\n",
    "print(\"‚úì Resultados guardados: data/processed/semi_supervised_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci√≥n de m√©todos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "colors = {'Supervised Baseline': 'red', 'Label Propagation': 'blue', 'Self-Training': 'green'}\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Graficar baseline\n",
    "    baseline_value = results_df[results_df['method'] == 'Supervised Baseline'][metric].values[0]\n",
    "    ax.axhline(y=baseline_value, color='red', linestyle='--', linewidth=2, label='Supervised Baseline')\n",
    "    \n",
    "    # Graficar Label Propagation\n",
    "    lp_data = results_df[results_df['method'] == 'Label Propagation']\n",
    "    ax.plot(lp_data['labeled_ratio'] * 100, lp_data[metric], 'bo-', linewidth=2, \n",
    "            markersize=8, label='Label Propagation')\n",
    "    \n",
    "    # Graficar Self-Training\n",
    "    st_data = results_df[results_df['method'] == 'Self-Training']\n",
    "    ax.plot(st_data['labeled_ratio'] * 100, st_data[metric], 'gs-', linewidth=2, \n",
    "            markersize=8, label='Self-Training')\n",
    "    \n",
    "    ax.set_xlabel('Porcentaje de Datos Etiquetados (%)', fontsize=11)\n",
    "    ax.set_ylabel(metric.replace('_', ' ').title(), fontsize=11)\n",
    "    ax.set_title(f'{metric.replace(\"_\", \" \").title()} vs Ratio de Labels', fontsize=12, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/07_semi_supervised_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°fico guardado: figures/07_semi_supervised_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ RESULTADOS Y CONCLUSIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN DE RESULTADOS - CLUSTERING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n‚úì N√∫mero √≥ptimo de clusters: {optimal_k}\")\n",
    "print(f\"\\nüìä M√©tricas por algoritmo:\")\n",
    "print(clustering_summary.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETACI√ìN:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. SILHOUETTE SCORE (rango: -1 a 1)\n",
    "   - Mide la similitud de un objeto con su cluster vs otros clusters\n",
    "   - Valores m√°s altos indican mejor separaci√≥n\n",
    "   - Interpretaci√≥n: > 0.5 (bueno), > 0.7 (excelente)\n",
    "\n",
    "2. DAVIES-BOULDIN INDEX (menor es mejor)\n",
    "   - Raz√≥n promedio de similitud intra-cluster vs inter-cluster\n",
    "   - Valores m√°s bajos indican clusters mejor definidos\n",
    "   - Interpretaci√≥n: < 1.0 (bueno), < 0.5 (excelente)\n",
    "\n",
    "3. COMPARACI√ìN CON RATINGS REALES\n",
    "   - Adjusted Rand Index mide acuerdo entre clustering y ratings\n",
    "   - Rango: -1 a 1 (1 = acuerdo perfecto, 0 = acuerdo aleatorio)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN DE RESULTADOS - SEMI-SUPERVISED LEARNING\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETACI√ìN:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. ACCURACY\n",
    "   - Proporci√≥n de predicciones correctas\n",
    "   - M√©trica general de rendimiento\n",
    "\n",
    "2. PRECISION\n",
    "   - Proporci√≥n de predicciones positivas que fueron correctas\n",
    "   - Importante cuando el costo de falsos positivos es alto\n",
    "\n",
    "3. RECALL\n",
    "   - Proporci√≥n de casos positivos que fueron identificados\n",
    "   - Importante cuando el costo de falsos negativos es alto\n",
    "\n",
    "4. F1-SCORE\n",
    "   - Media arm√≥nica entre Precision y Recall\n",
    "   - M√©trica equilibrada para clasificaci√≥n desbalanceada\n",
    "\n",
    "5. RATIO DE LABELS\n",
    "   - Proporci√≥n de datos etiquetados usados en entrenamiento\n",
    "   - Medir el impacto de tener menos datos etiquetados\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de clusters vs ratings\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AN√ÅLISIS DETALLADO: CLUSTERS K-MEANS vs RATINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "df_clustered = df.copy()\n",
    "df_clustered['cluster_kmeans'] = kmeans_labels\n",
    "df_clustered['cluster_agg'] = agg_labels\n",
    "df_clustered['cluster_dbscan'] = dbscan_labels\n",
    "\n",
    "print(\"\\nüìä Distribuci√≥n de ratings por cluster K-Means:\")\n",
    "crosstab = pd.crosstab(df_clustered['rating'], df_clustered['cluster_kmeans'], margins=True)\n",
    "print(crosstab)\n",
    "\n",
    "print(\"\\nüí° Observaciones:\")\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_clustered[df_clustered['cluster_kmeans'] == cluster]\n",
    "    rating_dist = cluster_data['rating'].value_counts()\n",
    "    print(f\"  Cluster {cluster}: {len(cluster_data)} cooperativas\")\n",
    "    print(f\"    Distribuci√≥n de ratings: {dict(rating_dist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusiones finales\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSIONES Y RECOMENDACIONES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "üéØ HALLAZGOS PRINCIPALES:\n",
    "\n",
    "1. CLUSTERING NO SUPERVISADO:\n",
    "   ‚Ä¢ Se identificaron patrones naturales en los datos financieros\n",
    "   ‚Ä¢ El n√∫mero √≥ptimo de clusters fue determinado mediante Silhouette Score\n",
    "   ‚Ä¢ K-Means proporciona una buena separaci√≥n de cooperativas\n",
    "   ‚Ä¢ Los clusters muestran cierta coherencia con los ratings reales\n",
    "\n",
    "2. COMPARACI√ìN CON RATINGS REALES:\n",
    "   ‚Ä¢ Existe una relaci√≥n parcial entre clusters y ratings\n",
    "   ‚Ä¢ Algunos ratings se distribuyen en m√∫ltiples clusters\n",
    "   ‚Ä¢ Sugiere que los indicadores financieros capturan matices no reflejados en ratings simples\n",
    "\n",
    "3. SEMI-SUPERVISED LEARNING:\n",
    "   ‚Ä¢ Label Propagation muestra mejor rendimiento con menos datos etiquetados\n",
    "   ‚Ä¢ Self-Training es m√°s inestable en ratios bajos\n",
    "   ‚Ä¢ Ambos m√©todos se acercan al baseline supervisado con ~50% de datos etiquetados\n",
    "\n",
    "üìå RECOMENDACIONES:\n",
    "\n",
    "   1. Para clasificaci√≥n de nuevas cooperativas:\n",
    "      ‚Üí Usar modelo supervisado con todos los datos disponibles\n",
    "      ‚Üí Si hay nuevas cooperativas sin etiquetar, aplicar Label Propagation\n",
    "\n",
    "   2. Para segmentaci√≥n de cooperativas:\n",
    "      ‚Üí K-Means proporciona grupos interpretables\n",
    "      ‚Üí Validar grupos con expertos en finanzas\n",
    "\n",
    "   3. Mejoras futuras:\n",
    "      ‚Üí Incluir m√°s indicadores financieros\n",
    "      ‚Üí Validaci√≥n cruzada temporal (datos hist√≥ricos)\n",
    "      ‚Üí An√°lisis de estabilidad de clusters\n",
    "      ‚Üí Investigar por qu√© algunos ratings se distribuyen en m√∫ltiples clusters\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados finales\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GUARDANDO RESULTADOS FINALES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Guardar datos clustered\n",
    "df_clustered.to_csv('data/processed/cooperativas_clustered.csv', index=False)\n",
    "print(\"‚úì Datos clustered guardados\")\n",
    "\n",
    "# Guardar m√©tricas\n",
    "clustering_summary.to_csv('data/processed/clustering_metrics.csv', index=False)\n",
    "results_df.to_csv('data/processed/semi_supervised_results.csv', index=False)\n",
    "print(\"‚úì M√©tricas guardadas\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis completado exitosamente\")\n",
    "print(\"\\nüìÅ Archivos generados:\")\n",
    "print(\"  ‚Ä¢ data/processed/cooperativas_data.csv\")\n",
    "print(\"  ‚Ä¢ data/processed/cooperativas_clustered.csv\")\n",
    "print(\"  ‚Ä¢ data/processed/clustering_metrics.csv\")\n",
    "print(\"  ‚Ä¢ data/processed/semi_supervised_results.csv\")\n",
    "print(\"  ‚Ä¢ figures/01_distribucion_por_rating.png\")\n",
    "print(\"  ‚Ä¢ figures/02_matriz_correlacion.png\")\n",
    "print(\"  ‚Ä¢ figures/03_tsne_visualization.png\")\n",
    "print(\"  ‚Ä¢ figures/04_elbow_analysis.png\")\n",
    "print(\"  ‚Ä¢ figures/05_clustering_results_tsne.png\")\n",
    "print(\"  ‚Ä¢ figures/06_confusion_matrices.png\")\n",
    "print(\"  ‚Ä¢ figures/07_semi_supervised_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Referencias y Metodolog√≠a\n",
    "\n",
    "### Fuentes Te√≥ricas\n",
    "\n",
    "1. **Clustering No Supervisado:**\n",
    "   - Lloyd, S. (1982). Least squares quantization in PCM. IEEE Transactions on Information Theory\n",
    "   - Rousseeuw, P. J. (1987). Silhouettes: a graphical aid to the interpretation of cluster analysis\n",
    "   - Davies, D. L., & Bouldin, D. W. (1979). A cluster separation measure\n",
    "\n",
    "2. **Semi-Supervised Learning:**\n",
    "   - Zhou, D., Bousquet, O., Lal, T. N., Weston, J., & Sch√∂lkopf, B. (2004). Learning with local and global consistency\n",
    "   - Rosenberg, D., Hebert, M., & Schneiderman, H. (2005). Semi-supervised self-training of object detection models\n",
    "\n",
    "3. **Visualizaci√≥n:**\n",
    "   - van der Maaten, L., & Hinton, G. (2008). Visualizing Data using t-SNE\n",
    "\n",
    "### Indicadores Financieros\n",
    "\n",
    "Referencia: Superintendencia de Econom√≠a Popular y Solidaria (SEPS)\n",
    "- https://www.seps.gob.ec\n",
    "- ASIS: Asociaci√≥n de Supervisores de Instituciones de Seguros\n",
    "- https://www.asis.fin.ec\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook generado:** Noviembre 2025\n",
    "\n",
    "**Pr√≥ximos pasos:**\n",
    "1. Obtener datos reales de cooperativas (archivos PDF)\n",
    "2. Validar resultados con expertos en finanzas\n",
    "3. Realizar an√°lisis temporal de estabilidad de clusters\n",
    "4. Investigar casos discrepantes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}